{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10cae63e",
   "metadata": {},
   "source": [
    "# CPU or GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5f13c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# # Configuración de TensorFlow para usar la GPU\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         for gpu in gpus:\n",
    "#             tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)\n",
    "\n",
    "# Configuración de TensorFlow para usar la CPU\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3386fa7f",
   "metadata": {},
   "source": [
    "# LIBRARIES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c130517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library EEG\n",
    "import mne\n",
    "\n",
    "# Library System \n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Library Statistics\n",
    "import scipy.stats\n",
    "import random\n",
    "from scipy.stats import entropy\n",
    "from scipy.fft import fft\n",
    "from scipy.signal import welch\n",
    "\n",
    "# Library GAN\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, BatchNormalization, Reshape, Conv2DTranspose, Conv2D, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Library Graph\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Library Visualitation\n",
    "from mne.minimum_norm import make_inverse_operator, apply_inverse\n",
    "\n",
    "# No Warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "mne.set_log_level(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597da088",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c1d2ba",
   "metadata": {},
   "source": [
    "# STATISTICS CALCULATES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1727c7",
   "metadata": {},
   "source": [
    "# INTERPOLACIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ad7a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# 1. Cargar y preparar los datos\n",
    "emotion='POSITIVE' # 'NEGATIVE' 'NEUTRAL'\n",
    "emotion_folder =f'C://Users//macka//TFM_WD//ORI//SEEDs_FIF_RECOG_GAN//{emotion}'\n",
    "file_list = [file for file in os.listdir(emotion_folder) if file.endswith('.fif')]\n",
    "\n",
    "eeg_data_list = []\n",
    "for file in file_list:\n",
    "    file_path = os.path.join(emotion_folder, file)\n",
    "    eeg_data = mne.io.read_raw_fif(file_path, preload=False)\n",
    "    eeg_data_list.append(eeg_data.get_data())\n",
    "\n",
    "channel_names=eeg_data.ch_names\n",
    "# Determine the common length for interpolation\n",
    "common_length =50000  # You can adjust this value depending on your needs\n",
    "\n",
    "interpolated_eeg_data_list = []\n",
    "\n",
    "for eeg_data in tqdm(eeg_data_list,leave=False):\n",
    "    num_channels = eeg_data.shape[0]\n",
    "    original_length = eeg_data.shape[1]\n",
    "    new_eeg_data = np.zeros((num_channels, common_length))\n",
    "\n",
    "    for ch_idx in range(num_channels):\n",
    "        x_original = np.linspace(0, 1, original_length)\n",
    "        x_new = np.linspace(0, 1, common_length)\n",
    "        new_eeg_data[ch_idx] = np.interp(x_new, x_original, eeg_data[ch_idx])\n",
    "\n",
    "    interpolated_eeg_data_list.append(new_eeg_data)\n",
    "\n",
    "eeg_data_tensor = np.stack(interpolated_eeg_data_list, axis=0).astype(np.float32)\n",
    "eeg_data_tensor = (eeg_data_tensor - np.min(eeg_data_tensor)) / (np.max(eeg_data_tensor) - np.min(eeg_data_tensor)) * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da65f6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_muestras = eeg_data_tensor.shape[0]\n",
    "num_canales = eeg_data_tensor.shape[1]\n",
    "num_puntos_por_canal = eeg_data_tensor.shape[2]\n",
    "\n",
    "# 2. Crear el modelo GAN\n",
    "# Generador\n",
    "def build_generator(latent_dim):\n",
    "    input_layer = Input(shape=(latent_dim,))\n",
    "\n",
    "    x = Dense(32)(input_layer)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(64)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(128)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(num_canales * num_puntos_por_canal, activation='tanh')(x)\n",
    "    output_layer = Reshape((num_canales, num_puntos_por_canal))(x)\n",
    "\n",
    "    return Model(input_layer, output_layer)\n",
    "\n",
    "# Discriminador\n",
    "def build_discriminator():\n",
    "    input_layer = Input(shape=(num_canales, num_puntos_por_canal))\n",
    "    x = Flatten()(input_layer)\n",
    "    x = Dense(128)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Dense(64)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Dense(32)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    return Model(input_layer, output_layer)\n",
    "\n",
    "# GAN\n",
    "def build_gan(generator, discriminator):\n",
    "    z = Input(shape=(latent_dim,))\n",
    "    generated_eeg = generator(z)\n",
    "    validity = discriminator(generated_eeg)\n",
    "\n",
    "    return Model(z, validity)\n",
    "\n",
    "latent_dim = 100\n",
    "generator = build_generator(latent_dim)\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "discriminator.trainable = False\n",
    "\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4312ca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train GAN\n",
    "epochs = 15\n",
    "batch_size = 32 # 16 Ultima que funciona\n",
    "half_batch = int(batch_size / 2)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Seleccionar un batch aleatorio de EEG reales\n",
    "    idx = np.random.randint(0, eeg_data_tensor.shape[0], half_batch)\n",
    "    real_eegs = eeg_data_tensor[idx]\n",
    "\n",
    "    # Generar un batch de EEG falsos\n",
    "    noise = np.random.normal(0, 1, (half_batch, latent_dim))\n",
    "    fake_eegs = generator.predict(noise)\n",
    "\n",
    "    # Entrenar el discriminador\n",
    "    real_loss = discriminator.train_on_batch(real_eegs, np.ones((half_batch, 1)))\n",
    "    fake_loss = discriminator.train_on_batch(fake_eegs, np.zeros((half_batch, 1)))\n",
    "    d_loss = 0.5 * np.add(real_loss, fake_loss)\n",
    "\n",
    "    # Entrenar el generador\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    g_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "    # Imprimir el progreso\n",
    "    print(f\"Epoch {epoch}/{epochs} [D loss: {d_loss[0]}, acc.: {100 * d_loss[1]}] [G loss: {g_loss}]\")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"El código tardó {elapsed_time:.2f} segundos en ejecutarse.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc18b54",
   "metadata": {},
   "source": [
    "**D_loss (Discriminator loss):** Es la pérdida del discriminador, que mide qué tan bien el discriminador puede distinguir entre datos reales y datos generados. Un valor bajo de D_loss indica que el discriminador tiene un buen rendimiento en la clasificación de los datos de entrada como reales o falsos.\n",
    "\n",
    "**acc. (Discriminator accuracy):** Es la precisión del discriminador, que mide el porcentaje de datos de entrada que el discriminador clasifica correctamente como reales o falsos.\n",
    "\n",
    "**G_loss (Generator loss):** Es la pérdida del generador, que mide qué tan bien el generador puede engañar al discriminador generando datos falsos que se parezcan a los datos reales. Un valor alto de G_loss indica que el generador necesita mejorar su capacidad para generar datos que parezcan reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35d99e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_artificial_eeg(generator, latent_dim):\n",
    "    # Generar ruido aleatorio con la dimensión latente\n",
    "    noise = np.random.normal(0, 1, (1, latent_dim))\n",
    "    \n",
    "    # Usar el generador para crear un EEG artificial a partir del ruido\n",
    "    artificial_eeg = generator.predict(noise)\n",
    "    \n",
    "    return artificial_eeg\n",
    "\n",
    "# Generar un EEG artificial\n",
    "generated_eeg = generate_artificial_eeg(generator, latent_dim)\n",
    "\n",
    "# # Opcional: Convertir el EEG artificial a su rango original de valores\n",
    "original_range_generated_eeg = (generated_eeg + 1) / 2 * (np.max(eeg_data_tensor) - np.min(eeg_data_tensor)) + np.min(eeg_data_tensor)\n",
    "\n",
    "np.save('generated_eeg.npy', generated_eeg)\n",
    "np.save('original_range_generated_eeg.npy', original_range_generated_eeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d21f345",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data_specifications = mne.io.read_raw_fif(file_path, preload=False)\n",
    "\n",
    "# Obtén el montaje del objeto Raw original\n",
    "montage=eeg_data_specifications.get_montage()\n",
    "\n",
    "# Obtén la información del objeto Raw original\n",
    "info = eeg_data_specifications.info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bff04db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un objeto Raw con los datos y la información de los canales\n",
    "eeg_generated_reshape=original_range_generated_eeg.reshape(62,50000)\n",
    "\n",
    "eeg_generated_reshape=eeg_generated_reshape/1000\n",
    "\n",
    "raw = mne.io.RawArray(eeg_generated_reshape, info)\n",
    "\n",
    "# Aplicar un montaje estándar (posiciones de los electrodos) para visualizar correctamente los datos\n",
    "raw.set_montage(montage)\n",
    "\n",
    "# Filtrar los datos\n",
    "raw.filter(l_freq=1, h_freq=52)\n",
    "\n",
    "# Crear un objeto Epochs a partir de los datos en bruto\n",
    "events = mne.make_fixed_length_events(raw, start=0, stop=raw.times[-1], duration=1)\n",
    "epochs = mne.Epochs(raw, events,tmin=0, tmax=1)\n",
    "\n",
    "# Calcular y visualizar el mapa cerebral\n",
    "evoked = epochs.average()\n",
    "evoked.plot_topomap(times=[0.1, 0.2, 0.3, 0.4, 0.5], ch_type='eeg', ncols=5)\n",
    "evoked.plot(time_unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9102dbf",
   "metadata": {},
   "source": [
    "###  Visualitation Original Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e860a3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data_original = mne.io.read_raw_fif(file_path, preload=True) #ultimo de la lista\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153f49ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar los datos\n",
    "eeg_data_original.filter(l_freq=1, h_freq=52)\n",
    "\n",
    "# Crear un objeto Epochs a partir de los datos en bruto\n",
    "events = mne.make_fixed_length_events(eeg_data_original, start=0, stop=eeg_data_original.times[-1], duration=1)\n",
    "epochs = mne.Epochs(eeg_data_original, events,tmin=0, tmax=1)\n",
    "\n",
    "# Calcular y visualizar el mapa cerebral\n",
    "evoked = epochs.average()\n",
    "evoked.plot_topomap(times=[0.1, 0.2, 0.3, 0.4, 0.5], ch_type='eeg', ncols=5)\n",
    "evoked.plot(time_unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7113ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
